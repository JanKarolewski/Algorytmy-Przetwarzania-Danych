# klasyfikator k najbliżyszch sasiadow dla wybranych cech 
import numpy as np
from scipy.spatial import distance
from sklearn.metrics import confusion_matrix

def sort(data, point):
    for i in range(len(data) - 1, 0, -1):
        for j in range(i):
            
            if distance.euclidean(data[j], point) > distance.euclidean(data[j+1], point):
                save = []
                save = data[j]
                data[j], data[j+1] = data[j+1], save
    return data


def euclidean_distance(point1, point2):
    euklidean = 0
    for i in range(len(point1)):
        euklidean = euklidean + np.sqrt((point1[i]-point1[i])**2+(point2[i]-point2[i])**2) # Pythagorean theorem
    return euklidean
                
    
    
count_correct = 0 
count_wrong = 0
kNN = np.array([train[0]])
k = 3 # kNN = np.append(kNN,[train[2]], axis = 0)
cechy1 = int(input("wprowadź nr cechy od: "))
cechy2 = int(input("wprowadź nr cechy do: "))
print(str(test[0][1]))
    
for i in range(len(np.array((test[:40])))):
    kNN = np.array([train[0]])
    
    for y in range(len(np.array((train)))):
        dst = distance.euclidean(test[i][cechy1:cechy2], train[y][cechy1:cechy2]) 
        
        for z in range(k):

            check_value = distance.euclidean(test[i][cechy1:cechy2], kNN[z][cechy1:cechy2])
                
            if len(np.array((kNN))) >= k:
                #wstaw w odpowiednie miejsce do macierzy kNN
                if dst < check_value:
                    kNN = np.insert(kNN, z, [train[y]], axis = 0)
                    kNN = np.delete(kNN, k, axis = 0)
                    kNN = sort(kNN,train[y])
                    break
                    

            if len(np.array((kNN))) < k:
                kNN = np.append(kNN,[train[y]], axis = 0)
                kNN =sort(kNN,train[y])
             
    
    results_test = {}
    
    y_true = []
    y_pred = []
    label_x = []
    label_y = []
    matrix = [] 
    
    for x in range(len(np.array((kNN)))):
        y_true = np.insert(y_true, x, str(test[x][0]))
        y_pred = np.insert(y_pred, x, str(test[x][0]))
        
        element = kNN[x][0]
        
        if element in results_test:
            results_test[element] += 1
            
        else: 
            results_test[element] = 1
            matrix = np.append(matrix, test[x][0])
            label_x = np.append(label_x, test[x][0])
            label_y = np.append(label_y, test[x][0])
 
    kNN_class = max(results_test, key=lambda x: results_test[x])

    if  int(np.array(test[i][0])) == kNN_class :
        count_correct += 1
    else:
        count_wrong += 1
    
    print(i)
    macierz = confusion_matrix(y_true, y_pred, labels= matrix)
    
    #Implementacja tablicy pomyłek
    print("Badany obiekt (jego klasa): " + str(test[i][0]))
    print("Badany obiekt (przypisana klasa): " + str(kNN_class))
    
    print("==============")
    


sum = count_correct+count_wrong
# print(count_correct)
# print(count_wrong)
print("sum: " + str(count_correct+count_wrong))
print("poprawnie sklasyfikowanych: " + str((count_correct/sum)*100) + " %" )
print("niepoprawnie sklasyfikowanych: " + str((count_wrong/sum)*100) + " %" )
print('end')
